{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92e35c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:28:02 | INFO | Starting T5 Question Generation Training\n",
      "16:28:02 | INFO | Loading model and tokenizer: google/flan-t5-base...\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "16:28:05 | INFO | Loading and processing datasets...\n",
      "16:28:05 | INFO | Loading FairytaleQA from: E:/A_CSE499/data\\FairytaleQA_train.csv\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
      "16:28:11 | INFO | Loaded 7573 samples from FairytaleQA\n",
      "16:28:11 | INFO | Loading FairytaleQA from: E:/A_CSE499/data\\FairytaleQA_validation.csv\n",
      "16:28:12 | INFO | Loaded 800 samples from FairytaleQA\n",
      "16:28:12 | INFO | Loading MCTest from: E:/A_CSE499/data\\mctest_train.csv\n",
      "16:28:14 | INFO | Loaded 2308 samples from MCTest\n",
      "16:28:14 | INFO | Loading MCTest from: E:/A_CSE499/data\\mctest_validation.csv\n",
      "16:28:14 | INFO | Loaded 260 samples from MCTest\n",
      "16:28:14 | INFO | Loading SQuAD from: E:/A_CSE499/data\\squad_train_v1.csv\n",
      "16:29:06 | INFO | Loaded 87680 samples from SQuAD\n",
      "16:29:06 | INFO | Loading SQuAD from: E:/A_CSE499/data\\squad_validation_v1.csv\n",
      "16:29:11 | INFO | Loaded 9862 samples from SQuAD\n",
      "16:29:11 | INFO | Loaded 97561 training samples and 10922 validation samples\n",
      "16:29:11 | INFO | Using default tokenizer.\n",
      "16:29:11 | INFO | === STARTING HYPERPARAMETER TUNING ===\n",
      "[I 2025-11-19 16:29:13,869] Using an existing study with name 't5-qg-tuning' instead of creating a new one.\n",
      "16:29:13 | INFO | Study already has 10 completed trials. Skipping optimization.\n",
      "16:29:13 | INFO | === TUNING COMPLETE ===\n",
      "16:29:13 | INFO | Best trial number: 9\n",
      "16:29:13 | INFO | Best BLEU-4: 0.0637\n",
      "16:29:13 | INFO | Best hyperparameters: {\n",
      "  \"learning_rate\": 3.961867790406586e-05,\n",
      "  \"weight_decay\": 0.09218742350231168,\n",
      "  \"lr_scheduler_type\": \"cosine\",\n",
      "  \"warmup_steps\": 2051\n",
      "}\n",
      "16:29:13 | INFO | === STARTING FINAL TRAINING WITH BEST HYPERPARAMETERS ===\n",
      "16:29:15 | INFO | Training Configuration: Dataset size: 97,561, Effective batch size: 16, Steps per epoch: 6097\n",
      "16:29:18 | INFO | === FINAL TRAINING START ===\n",
      "16:29:18 | INFO | FINAL TRAINING START GPU Memory - Allocated: 0.93GB, Reserved: 0.99GB\n",
      "16:29:18 | INFO | FINAL TRAINING START Model - Training mode: False, Device: cuda:0\n",
      "16:29:18 | INFO | Starting final training...\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48784' max='48784' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48784/48784 26:59:06, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:36:44 | INFO | Epoch 0.10 | Loss: 1.9151 | LR: 1.17e-05\n",
      "16:41:34 | INFO | Epoch 0.20 | Loss: 1.8208 | LR: 2.35e-05\n",
      "16:46:20 | INFO | Epoch 0.30 | Loss: 1.8171 | LR: 3.53e-05\n",
      "16:51:06 | INFO | Epoch 0.40 | Loss: 1.7906 | LR: 3.96e-05\n",
      "16:55:51 | INFO | Epoch 0.50 | Loss: 1.7709 | LR: 3.96e-05\n",
      "17:00:38 | INFO | Epoch 0.60 | Loss: 1.7694 | LR: 3.95e-05\n",
      "17:05:24 | INFO | Epoch 0.70 | Loss: 1.7214 | LR: 3.94e-05\n",
      "17:10:10 | INFO | Epoch 0.80 | Loss: 1.7391 | LR: 3.93e-05\n",
      "17:14:56 | INFO | Epoch 0.90 | Loss: 1.7407 | LR: 3.91e-05\n",
      "17:19:42 | INFO | Epoch 1.00 | Loss: 1.7228 | LR: 3.89e-05\n",
      "17:20:20 | INFO | ===== Average Training Loss for Epoch 1: 1.7808 =====\n",
      "17:20:20 | INFO | === BEFORE EVALUATION ===\n",
      "17:20:20 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 6.38GB\n",
      "17:20:20 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "17:20:28 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 1:   0%|          | 0/5461 [00:00<?, ?batch/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Group Beam Search is scheduled to be moved to a `custom_generate` repository in v4.55.0. To prevent loss of backward compatibility, add `trust_remote_code=True` to your `generate` call.\n",
      "Evaluating Epoch 1: 100%|██████████| 5461/5461 [1:34:50<00:00,  1.04s/batch]\n",
      "18:55:19 | INFO | Computing metrics for 10922 predictions...\n",
      "18:55:19 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 1\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1962 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1132 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0783 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0596 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2578 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2579 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8896 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9927 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9927 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.066  |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1489 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5683 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:54:25 | INFO | === AFTER EVALUATION ===\n",
      "19:54:25 | INFO | AFTER EVAL GPU Memory - Allocated: 2.82GB, Reserved: 3.05GB\n",
      "19:54:25 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "19:54:25 | INFO | Evaluation completed successfully. Average loss: 1.5683\n",
      "19:59:29 | INFO | Epoch 1.10 | Loss: 1.6547 | LR: 3.87e-05\n",
      "20:04:16 | INFO | Epoch 1.20 | Loss: 1.6417 | LR: 3.84e-05\n",
      "20:09:01 | INFO | Epoch 1.30 | Loss: 1.6573 | LR: 3.81e-05\n",
      "20:13:47 | INFO | Epoch 1.40 | Loss: 1.6408 | LR: 3.78e-05\n",
      "20:18:32 | INFO | Epoch 1.50 | Loss: 1.6559 | LR: 3.74e-05\n",
      "20:23:17 | INFO | Epoch 1.60 | Loss: 1.6440 | LR: 3.70e-05\n",
      "20:28:04 | INFO | Epoch 1.70 | Loss: 1.6348 | LR: 3.66e-05\n",
      "20:32:50 | INFO | Epoch 1.80 | Loss: 1.6348 | LR: 3.62e-05\n",
      "20:37:36 | INFO | Epoch 1.90 | Loss: 1.6281 | LR: 3.57e-05\n",
      "20:42:21 | INFO | Epoch 2.00 | Loss: 1.6379 | LR: 3.52e-05\n",
      "20:42:28 | INFO | ===== Average Training Loss for Epoch 2: 1.6430 =====\n",
      "20:42:28 | INFO | === BEFORE EVALUATION ===\n",
      "20:42:28 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.61GB\n",
      "20:42:28 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "20:42:37 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 2: 100%|██████████| 5461/5461 [1:36:09<00:00,  1.06s/batch]\n",
      "22:18:47 | INFO | Computing metrics for 10922 predictions...\n",
      "22:18:47 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 2\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1928 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1112 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0769 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0585 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2567 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2569 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8892 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9929 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9929 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0672 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1536 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5383 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:17:15 | INFO | === AFTER EVALUATION ===\n",
      "23:17:15 | INFO | AFTER EVAL GPU Memory - Allocated: 2.82GB, Reserved: 3.04GB\n",
      "23:17:15 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "23:17:15 | INFO | Evaluation completed successfully. Average loss: 1.5383\n",
      "23:22:15 | INFO | Epoch 2.10 | Loss: 1.5758 | LR: 3.47e-05\n",
      "23:27:01 | INFO | Epoch 2.20 | Loss: 1.5641 | LR: 3.41e-05\n",
      "23:31:48 | INFO | Epoch 2.30 | Loss: 1.5517 | LR: 3.36e-05\n",
      "23:36:35 | INFO | Epoch 2.40 | Loss: 1.5555 | LR: 3.30e-05\n",
      "23:41:21 | INFO | Epoch 2.50 | Loss: 1.5503 | LR: 3.23e-05\n",
      "23:46:07 | INFO | Epoch 2.60 | Loss: 1.5529 | LR: 3.17e-05\n",
      "23:50:54 | INFO | Epoch 2.70 | Loss: 1.5498 | LR: 3.10e-05\n",
      "23:55:41 | INFO | Epoch 2.80 | Loss: 1.5511 | LR: 3.04e-05\n",
      "00:00:27 | INFO | Epoch 2.90 | Loss: 1.5492 | LR: 2.97e-05\n",
      "00:05:14 | INFO | Epoch 3.00 | Loss: 1.5538 | LR: 2.90e-05\n",
      "00:05:24 | INFO | ===== Average Training Loss for Epoch 3: 1.5554 =====\n",
      "00:05:24 | INFO | === BEFORE EVALUATION ===\n",
      "00:05:24 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.54GB\n",
      "00:05:24 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "00:05:33 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 3: 100%|██████████| 5461/5461 [1:36:03<00:00,  1.06s/batch]\n",
      "01:41:36 | INFO | Computing metrics for 10922 predictions...\n",
      "01:41:36 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 3\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1941 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1125 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0782 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0594 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2575 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2581 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.889  |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9933 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9933 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0664 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1531 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |    1.53 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:40:40 | INFO | === AFTER EVALUATION ===\n",
      "02:40:40 | INFO | AFTER EVAL GPU Memory - Allocated: 2.82GB, Reserved: 3.03GB\n",
      "02:40:40 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "02:40:40 | INFO | Evaluation completed successfully. Average loss: 1.5300\n",
      "02:45:37 | INFO | Epoch 3.10 | Loss: 1.4986 | LR: 2.82e-05\n",
      "02:50:22 | INFO | Epoch 3.20 | Loss: 1.4919 | LR: 2.75e-05\n",
      "02:55:08 | INFO | Epoch 3.30 | Loss: 1.4794 | LR: 2.67e-05\n",
      "02:59:54 | INFO | Epoch 3.40 | Loss: 1.4839 | LR: 2.60e-05\n",
      "03:04:41 | INFO | Epoch 3.50 | Loss: 1.4989 | LR: 2.52e-05\n",
      "03:09:27 | INFO | Epoch 3.60 | Loss: 1.4929 | LR: 2.44e-05\n",
      "03:14:13 | INFO | Epoch 3.70 | Loss: 1.4992 | LR: 2.36e-05\n",
      "03:18:59 | INFO | Epoch 3.80 | Loss: 1.4908 | LR: 2.28e-05\n",
      "03:23:46 | INFO | Epoch 3.89 | Loss: 1.4754 | LR: 2.20e-05\n",
      "03:28:33 | INFO | Epoch 3.99 | Loss: 1.4719 | LR: 2.12e-05\n",
      "03:28:47 | INFO | ===== Average Training Loss for Epoch 4: 1.4883 =====\n",
      "03:28:47 | INFO | === BEFORE EVALUATION ===\n",
      "03:28:47 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.58GB\n",
      "03:28:47 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "03:28:56 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 4: 100%|██████████| 5461/5461 [1:36:03<00:00,  1.06s/batch]\n",
      "05:04:59 | INFO | Computing metrics for 10922 predictions...\n",
      "05:04:59 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 4\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1951 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1133 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0791 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0604 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2581 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2576 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8893 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9926 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9926 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0665 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1537 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5295 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06:03:44 | INFO | === AFTER EVALUATION ===\n",
      "06:03:44 | INFO | AFTER EVAL GPU Memory - Allocated: 2.82GB, Reserved: 3.04GB\n",
      "06:03:44 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "06:03:44 | INFO | Evaluation completed successfully. Average loss: 1.5295\n",
      "06:08:36 | INFO | Epoch 4.09 | Loss: 1.4464 | LR: 2.04e-05\n",
      "06:13:22 | INFO | Epoch 4.19 | Loss: 1.4328 | LR: 1.96e-05\n",
      "06:18:07 | INFO | Epoch 4.29 | Loss: 1.4370 | LR: 1.88e-05\n",
      "06:22:52 | INFO | Epoch 4.39 | Loss: 1.4418 | LR: 1.80e-05\n",
      "06:27:39 | INFO | Epoch 4.49 | Loss: 1.4365 | LR: 1.72e-05\n",
      "06:32:26 | INFO | Epoch 4.59 | Loss: 1.4422 | LR: 1.64e-05\n",
      "06:37:12 | INFO | Epoch 4.69 | Loss: 1.4372 | LR: 1.56e-05\n",
      "06:41:58 | INFO | Epoch 4.79 | Loss: 1.4343 | LR: 1.48e-05\n",
      "06:46:44 | INFO | Epoch 4.89 | Loss: 1.4321 | LR: 1.40e-05\n",
      "06:51:31 | INFO | Epoch 4.99 | Loss: 1.4404 | LR: 1.32e-05\n",
      "06:51:49 | INFO | ===== Average Training Loss for Epoch 5: 1.4381 =====\n",
      "06:51:49 | INFO | === BEFORE EVALUATION ===\n",
      "06:51:49 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.57GB\n",
      "06:51:49 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "06:51:57 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 5: 100%|██████████| 5461/5461 [1:35:01<00:00,  1.04s/batch]\n",
      "08:26:58 | INFO | Computing metrics for 10922 predictions...\n",
      "08:26:58 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 5\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.197  |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1148 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0801 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.061  |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2605 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2604 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8898 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9918 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9918 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0669 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1536 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5261 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:25:15 | INFO | === AFTER EVALUATION ===\n",
      "09:25:15 | INFO | AFTER EVAL GPU Memory - Allocated: 2.81GB, Reserved: 3.04GB\n",
      "09:25:15 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "09:25:15 | INFO | Evaluation completed successfully. Average loss: 1.5261\n",
      "09:30:05 | INFO | Epoch 5.09 | Loss: 1.4006 | LR: 1.25e-05\n",
      "09:34:50 | INFO | Epoch 5.19 | Loss: 1.4038 | LR: 1.17e-05\n",
      "09:39:36 | INFO | Epoch 5.29 | Loss: 1.3998 | LR: 1.10e-05\n",
      "09:44:23 | INFO | Epoch 5.39 | Loss: 1.3964 | LR: 1.03e-05\n",
      "09:49:09 | INFO | Epoch 5.49 | Loss: 1.4050 | LR: 9.57e-06\n",
      "09:53:56 | INFO | Epoch 5.59 | Loss: 1.4030 | LR: 8.89e-06\n",
      "09:58:41 | INFO | Epoch 5.69 | Loss: 1.4150 | LR: 8.22e-06\n",
      "10:03:28 | INFO | Epoch 5.79 | Loss: 1.4080 | LR: 7.57e-06\n",
      "10:08:14 | INFO | Epoch 5.89 | Loss: 1.3948 | LR: 6.95e-06\n",
      "10:13:00 | INFO | Epoch 5.99 | Loss: 1.4047 | LR: 6.34e-06\n",
      "10:13:23 | INFO | ===== Average Training Loss for Epoch 6: 1.4031 =====\n",
      "10:13:23 | INFO | === BEFORE EVALUATION ===\n",
      "10:13:23 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.62GB\n",
      "10:13:23 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "10:13:31 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 6: 100%|██████████| 5461/5461 [1:35:15<00:00,  1.05s/batch]\n",
      "11:48:47 | INFO | Computing metrics for 10922 predictions...\n",
      "11:48:47 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 6\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1996 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1165 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0813 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0621 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2627 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2614 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8903 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9921 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9921 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0662 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1515 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5264 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:46:36 | INFO | === AFTER EVALUATION ===\n",
      "12:46:36 | INFO | AFTER EVAL GPU Memory - Allocated: 2.81GB, Reserved: 3.02GB\n",
      "12:46:36 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "12:46:36 | INFO | Evaluation completed successfully. Average loss: 1.5264\n",
      "12:51:22 | INFO | Epoch 6.09 | Loss: 1.3749 | LR: 5.76e-06\n",
      "12:56:08 | INFO | Epoch 6.19 | Loss: 1.3699 | LR: 5.20e-06\n",
      "13:00:53 | INFO | Epoch 6.29 | Loss: 1.3810 | LR: 4.66e-06\n",
      "13:05:40 | INFO | Epoch 6.39 | Loss: 1.3793 | LR: 4.15e-06\n",
      "13:10:26 | INFO | Epoch 6.49 | Loss: 1.3982 | LR: 3.67e-06\n",
      "13:15:13 | INFO | Epoch 6.59 | Loss: 1.3821 | LR: 3.21e-06\n",
      "13:20:01 | INFO | Epoch 6.69 | Loss: 1.3757 | LR: 2.78e-06\n",
      "13:24:47 | INFO | Epoch 6.79 | Loss: 1.3836 | LR: 2.38e-06\n",
      "13:29:33 | INFO | Epoch 6.89 | Loss: 1.3799 | LR: 2.01e-06\n",
      "13:34:19 | INFO | Epoch 6.99 | Loss: 1.3925 | LR: 1.67e-06\n",
      "13:34:45 | INFO | ===== Average Training Loss for Epoch 7: 1.3817 =====\n",
      "13:34:45 | INFO | === BEFORE EVALUATION ===\n",
      "13:34:45 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.61GB\n",
      "13:34:45 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "13:34:54 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 7: 100%|██████████| 5461/5461 [1:35:35<00:00,  1.05s/batch]\n",
      "15:10:29 | INFO | Computing metrics for 10922 predictions...\n",
      "15:10:29 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 7\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1998 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.117  |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0819 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0624 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.263  |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2626 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8902 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9922 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9922 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0669 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1534 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5286 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:08:33 | INFO | === AFTER EVALUATION ===\n",
      "16:08:33 | INFO | AFTER EVAL GPU Memory - Allocated: 2.81GB, Reserved: 3.03GB\n",
      "16:08:33 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "16:08:33 | INFO | Evaluation completed successfully. Average loss: 1.5286\n",
      "16:13:14 | INFO | Epoch 7.09 | Loss: 1.3737 | LR: 1.36e-06\n",
      "16:18:00 | INFO | Epoch 7.19 | Loss: 1.3689 | LR: 1.08e-06\n",
      "16:22:46 | INFO | Epoch 7.29 | Loss: 1.3756 | LR: 8.33e-07\n",
      "16:27:35 | INFO | Epoch 7.39 | Loss: 1.3672 | LR: 6.16e-07\n",
      "16:32:21 | INFO | Epoch 7.49 | Loss: 1.3725 | LR: 4.31e-07\n",
      "16:37:07 | INFO | Epoch 7.59 | Loss: 1.3803 | LR: 2.79e-07\n",
      "16:41:54 | INFO | Epoch 7.69 | Loss: 1.3695 | LR: 1.60e-07\n",
      "16:46:41 | INFO | Epoch 7.79 | Loss: 1.3717 | LR: 7.36e-08\n",
      "16:51:26 | INFO | Epoch 7.89 | Loss: 1.3694 | LR: 2.03e-08\n",
      "16:56:12 | INFO | Epoch 7.99 | Loss: 1.3727 | LR: 1.89e-10\n",
      "16:56:42 | INFO | ===== Average Training Loss for Epoch 8: 1.3721 =====\n",
      "16:56:42 | INFO | === BEFORE EVALUATION ===\n",
      "16:56:42 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 5.56GB\n",
      "16:56:42 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "16:56:50 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 8: 100%|██████████| 5461/5461 [1:35:35<00:00,  1.05s/batch]\n",
      "18:32:26 | INFO | Computing metrics for 10922 predictions...\n",
      "18:32:26 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 8\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.1991 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1168 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0817 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0622 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2625 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.262  |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.89   |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9929 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9929 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0667 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.1528 |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5317 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:30:42 | INFO | === AFTER EVALUATION ===\n",
      "19:30:42 | INFO | AFTER EVAL GPU Memory - Allocated: 2.82GB, Reserved: 3.03GB\n",
      "19:30:42 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "19:30:42 | INFO | Evaluation completed successfully. Average loss: 1.5317\n",
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING SUMMARY\n",
      "================================================================================\n",
      "+--------------+--------------+---------------+\n",
      "| Metric       |   Best Score | Achieved At   |\n",
      "+==============+==============+===============+\n",
      "| Best BLEU-4  |       0.0624 | Epoch 7       |\n",
      "+--------------+--------------+---------------+\n",
      "| Best ROUGE-L |       0.263  | Epoch 7       |\n",
      "+--------------+--------------+---------------+\n",
      "| Best METEOR  |       0.2626 | Epoch 7       |\n",
      "+--------------+--------------+---------------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19:31:05 | INFO | Saving final model...\n",
      "19:31:10 | INFO | Performing final comprehensive evaluation...\n",
      "19:31:10 | INFO | === BEFORE EVALUATION ===\n",
      "19:31:10 | INFO | BEFORE EVAL GPU Memory - Allocated: 2.80GB, Reserved: 3.03GB\n",
      "19:31:10 | INFO | BEFORE EVAL Model - Training mode: True, Device: cuda:0\n",
      "19:31:18 | INFO | Starting evaluation on full validation set...\n",
      "Evaluating Epoch 8: 100%|██████████| 5461/5461 [1:35:23<00:00,  1.05s/batch]\n",
      "21:06:41 | INFO | Computing metrics for 10922 predictions...\n",
      "21:06:41 | INFO | Computing quality and diversity metrics...\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Adeptus_Mechanicus\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION RESULTS - Epoch 8\n",
      "================================================================================\n",
      "\n",
      "QUALITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| BLEU-1     |  0.2005 |\n",
      "+------------+---------+\n",
      "| BLEU-2     |  0.1177 |\n",
      "+------------+---------+\n",
      "| BLEU-3     |  0.0824 |\n",
      "+------------+---------+\n",
      "| BLEU-4     |  0.0629 |\n",
      "+------------+---------+\n",
      "| ROUGE-L    |  0.2636 |\n",
      "+------------+---------+\n",
      "| METEOR     |  0.2633 |\n",
      "+------------+---------+\n",
      "| BERT-SCORE |  0.8903 |\n",
      "+------------+---------+\n",
      "| SELF-BLEU  |  0.9925 |\n",
      "+------------+---------+\n",
      "\n",
      "DIVERSITY METRICS:\n",
      "+------------+---------+\n",
      "| Metric     |   Score |\n",
      "+============+=========+\n",
      "| SELF-BLEU  |  0.9925 |\n",
      "+------------+---------+\n",
      "| DISTINCT-1 |  0.0668 |\n",
      "+------------+---------+\n",
      "| DISTINCT-2 |  0.153  |\n",
      "+------------+---------+\n",
      "\n",
      "OTHER METRICS:\n",
      "+----------+---------+\n",
      "| Metric   |   Score |\n",
      "+==========+=========+\n",
      "| LOSS     |  1.5307 |\n",
      "+----------+---------+\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:04:38 | INFO | === AFTER EVALUATION ===\n",
      "22:04:38 | INFO | AFTER EVAL GPU Memory - Allocated: 2.81GB, Reserved: 3.03GB\n",
      "22:04:38 | INFO | AFTER EVAL Model - Training mode: True, Device: cuda:0\n",
      "22:04:38 | INFO | Evaluation completed successfully. Average loss: 1.5307\n",
      "22:04:38 | INFO | Generating sample predictions...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "SAMPLE PREDICTIONS - 20 Context-Question Pairs\n",
      "====================================================================================================\n",
      "\n",
      "--- SAMPLE  1 ---\n",
      "CONTEXT: Gasquet (1908) claimed that the Latin name atra mors (Black Death) for the 14th-century epidemic first appeared in modern times in 1631 in a book on Danish history by J.I. Pontanus: \"Vulgo & ab effect...\n",
      "ACTUAL:   What is the Latin name for Black Death?\n",
      "PREDICTED: In what year did Gasquet claim the Latin name atra mors first appear in modern times?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  2 ---\n",
      "CONTEXT: West is one of the best-selling artists of all time, having sold more than 32 million albums and 100 million digital downloads worldwide. He has won a total of 21 Grammy Awards, making him one of the ...\n",
      "ACTUAL:   How many Grammy Awards has Kanye West won?\n",
      "PREDICTED: How many albums has Kanye sold worldwide?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  3 ---\n",
      "CONTEXT: Galicia was spared the worst of the fighting in that war: it was one of the areas where the initial coup attempt at the outset of the war was successful, and it remained in Nationalist (Franco's army'...\n",
      "ACTUAL:   Which prominent journalist was victim of the killings?\n",
      "PREDICTED: Who was the wife of the governor of A Corua?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  4 ---\n",
      "CONTEXT: Tucson (/ˈtuːsɒn/ /tuːˈsɒn/) is a city and the county seat of Pima County, Arizona, United States, and home to the University of Arizona. The 2010 United States Census put the population at 520,116, w...\n",
      "ACTUAL:   How far is Tucson from Mexico?\n",
      "PREDICTED: What is Tucson's nickname?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  5 ---\n",
      "CONTEXT: In 1977, Schwarzenegger's autobiography/weight-training guide Arnold: The Education of a Bodybuilder was published and became a huge success. After taking English classes at Santa Monica College in Ca...\n",
      "ACTUAL:   At what college did Schwarzenegger study but not receive his degree?\n",
      "PREDICTED: In what year was Schwarzenegger's book Arnold: The Education of a Bodybuilder published?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  6 ---\n",
      "CONTEXT: During the war, the Paris National Guard, particularly in the working-class neighbourhoods of Paris, had become highly politicised and units elected officers; many refused to wear uniforms or obey com...\n",
      "ACTUAL:   On which dates did La Semaine Sanglante occur in Paris?\n",
      "PREDICTED: When did the Paris National Guard try to seize power?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  7 ---\n",
      "CONTEXT: A number of new Presbyterian Churches were founded by Scottish immigrants to England in the 19th century and later. Following the 'Disruption' in 1843 many of those linked to the Church of Scotland ev...\n",
      "ACTUAL:   When was the earliest Presbyterian churches founded by Scotland in England?\n",
      "PREDICTED: What is the name of the congregation in the heart of London's financial district?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  8 ---\n",
      "CONTEXT: Bacteria often attach to surfaces and form dense aggregations called biofilms or bacterial mats. These films can range from a few micrometers in thickness to up to half a meter in depth, and may conta...\n",
      "ACTUAL:   Which bacteria is more difficult to eradicate?\n",
      "PREDICTED: Bacteria often attach to surfaces and form dense aggregations called what?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE  9 ---\n",
      "CONTEXT: On June 17, 2015, 21-year-old Dylann Roof entered the historic Emanuel African Methodist Episcopal Church during a Bible study and killed nine people. Senior pastor Clementa Pinckney, who also served ...\n",
      "ACTUAL:   What was the name of 21 year old that killed nine church members in Charleston, South Carolina?\n",
      "PREDICTED: Who was the pastor of the Emanuel African Methodist Episcopal Church?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 10 ---\n",
      "CONTEXT: Many popular museums, such as the San Diego Museum of Art, the San Diego Natural History Museum, the San Diego Museum of Man, the Museum of Photographic Arts, and the San Diego Air & Space Museum are ...\n",
      "ACTUAL:   Where can one find the San Diego Zoo?\n",
      "PREDICTED: Where is the Museum of Contemporary Art San Diego located?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 11 ---\n",
      "CONTEXT: Hyderabad's lakes and the sloping terrain of its low-lying hills provide habitat for an assortment of flora and fauna. The forest region in and around the city encompasses areas of ecological and biol...\n",
      "ACTUAL:   Hyderabad's largest zoo is known as India's first to have what two kinds of animals in a safari park setting?\n",
      "PREDICTED: How many national parks does Hyderabad have?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 12 ---\n",
      "CONTEXT: then she began to say that the schoolmaster was such a strong and able man , and finally , that she and her daughter would like to have him for priest , and whether he would not stay and succeed the o...\n",
      "ACTUAL:   why did the schoolmaster ask for a year to think it over ?\n",
      "PREDICTED: why did the schoolmaster ask for a year to think it over ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 13 ---\n",
      "CONTEXT: Arsenal's parent company, Arsenal Holdings plc, operates as a non-quoted public limited company, whose ownership is considerably different from that of other football clubs. Only 62,217 shares in Arse...\n",
      "ACTUAL:   How many shares of Arsenal stock are there?\n",
      "PREDICTED: How many shares in Arsenal have been issued?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 14 ---\n",
      "CONTEXT: Sometimes only partial compliance with license agreements is the cause. For example, in 2013, the US Army settled a lawsuit with Texas-based company Apptricity, which makes software that allows the ar...\n",
      "ACTUAL:   What is a possible cause of copyright infringement?\n",
      "PREDICTED: How much did the US Army pay for a license in 2004?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 15 ---\n",
      "CONTEXT: they filled it completely and more , and still more of them came in . then the walls began to crack , and the little hut spread out at all corners , and grew so splendid and magnificent that the wealt...\n",
      "ACTUAL:   who was the only one who did not dance ?\n",
      "PREDICTED: what did andrew do under cover of the noise ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 16 ---\n",
      "CONTEXT: Only a few contemporary societies are classified as hunter-gatherers, and many supplement their foraging activity with horticulture and/or keeping animals.\n",
      "ACTUAL:   How many groups of modern hunter-gatherers are there?\n",
      "PREDICTED: What do hunter-gatherers supplement their foraging activity with?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 17 ---\n",
      "CONTEXT: Due to insistence by the International Federation of Association Football (FIFA), the international governing body of football, that domestic leagues reduce the number of games clubs played, the numbe...\n",
      "ACTUAL:   On which date did FIFA request that all European leagues reduce the number of teams within themselves to 18?\n",
      "PREDICTED: When did FIFA request that all major European leagues be reduced to 18 teams?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 18 ---\n",
      "CONTEXT: the two snakes looked at each other in dismay . the ring and the casket were the only things they did not want her to have . then after a short pause they spoke . ' why do you want the ring and casket...\n",
      "ACTUAL:   what did the girl do after she stopped under a grove of palm trees ?\n",
      "PREDICTED: why did the two snakes look at each other in dismay ?\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- SAMPLE 19 ---\n",
      "CONTEXT: Plant physiology encompasses all the internal chemical and physical activities of plants associated with life. Chemicals obtained from the air, soil and water form the basis of all plant metabolism. T...\n",
      "ACTUAL:   Is respiration in animals similar to photosynthesis in plants?\n",
      "PREDICTED: What is the opposite of photosynthesis?\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:04:55 | INFO | Training pipeline completed successfully!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SAMPLE 20 ---\n",
      "CONTEXT: One use of the term \"computer security\" refers to technology that is used to implement secure operating systems. In the 1980s the United States Department of Defense (DoD) used the \"Orange Book\" stand...\n",
      "ACTUAL:   What is an example of a system that meets EAL6?\n",
      "PREDICTED: What does EAL6 stand for?\n",
      "--------------------------------------------------------------------------------\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "****************************************\n",
      "TRAINING COMPLETED SUCCESSFULLY!\n",
      "****************************************\n",
      "\n",
      "FINAL EVALUATION RESULTS (using best params):\n",
      "╒════════════╤═══════════════╕\n",
      "│ Metric     │   Final Score │\n",
      "╞════════════╪═══════════════╡\n",
      "│ EPOCH      │        8      │\n",
      "├────────────┼───────────────┤\n",
      "│ BERT_SCORE │        0.8903 │\n",
      "├────────────┼───────────────┤\n",
      "│ BLEU_1     │        0.2005 │\n",
      "├────────────┼───────────────┤\n",
      "│ BLEU_2     │        0.1177 │\n",
      "├────────────┼───────────────┤\n",
      "│ BLEU_3     │        0.0824 │\n",
      "├────────────┼───────────────┤\n",
      "│ BLEU_4     │        0.0629 │\n",
      "├────────────┼───────────────┤\n",
      "│ DISTINCT_1 │        0.0668 │\n",
      "├────────────┼───────────────┤\n",
      "│ DISTINCT_2 │        0.153  │\n",
      "├────────────┼───────────────┤\n",
      "│ LOSS       │        1.5307 │\n",
      "├────────────┼───────────────┤\n",
      "│ METEOR     │        0.2633 │\n",
      "├────────────┼───────────────┤\n",
      "│ ROUGE_L    │        0.2636 │\n",
      "├────────────┼───────────────┤\n",
      "│ SELF_BLEU  │        0.9925 │\n",
      "╘════════════╧═══════════════╛\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import transformers\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerCallback,\n",
    "    TrainerState,\n",
    "    TrainerControl,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from transformers.trainer_utils import set_seed\n",
    "import evaluate\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "import bert_score\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from tabulate import tabulate\n",
    "from transformers.utils.logging import set_verbosity_error\n",
    "import gc\n",
    "import optuna  # --- NEW ---\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Setup logging for VS Code\n",
    "def setup_logging():\n",
    "    \"\"\"Setup logging configuration\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "        datefmt='%H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.StreamHandler(),\n",
    "            logging.FileHandler('training.log', encoding='utf-8')\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "\n",
    "logger = setup_logging()\n",
    "#set_verbosity_error()\n",
    "\n",
    "# Ensure NLTK data is available\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "class QuestionGenerationDataset(Dataset):\n",
    "    def __init__(self, contexts, questions, tokenizer, max_length=512):\n",
    "        self.contexts = contexts\n",
    "        self.questions = questions\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.contexts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = self.contexts[idx]\n",
    "        question = self.questions[idx]\n",
    "\n",
    "        input_text = f\"Generate a question from context: {context}\"\n",
    "\n",
    "        input_encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length=self.max_length,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        target_encoding = self.tokenizer(\n",
    "            question,\n",
    "            max_length=128,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_encoding.input_ids.flatten(),\n",
    "            \"attention_mask\": input_encoding.attention_mask.flatten(),\n",
    "            \"labels\": target_encoding.input_ids.flatten()\n",
    "        }\n",
    "\n",
    "class DataProcessor:\n",
    "    def __init__(self, data_dir, tokenizer):\n",
    "        self.data_dir = data_dir\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def load_fairytale_qa(self, file_path: str) -> Tuple[List[str], List[str]]:\n",
    "        contexts, questions = [], []\n",
    "        if os.path.exists(file_path):\n",
    "            logger.info(f\"Loading FairytaleQA from: {file_path}\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "                for _, row in df.iterrows():\n",
    "                    if pd.notna(row.get('context', '')) and pd.notna(row.get('question', '')):\n",
    "                        context, question = str(row['context']).strip(), str(row['question']).strip()\n",
    "                        if context and question and len(self.tokenizer.encode(context)) < 512:\n",
    "                            contexts.append(context)\n",
    "                            questions.append(question)\n",
    "                logger.info(f\"Loaded {len(contexts)} samples from FairytaleQA\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "        else:\n",
    "            logger.warning(f\"File not found: {file_path}\")\n",
    "        return contexts, questions\n",
    "\n",
    "    def load_mctest(self, file_path: str) -> Tuple[List[str], List[str]]:\n",
    "        contexts, questions = [], []\n",
    "        if os.path.exists(file_path):\n",
    "            logger.info(f\"Loading MCTest from: {file_path}\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "                for _, row in df.iterrows():\n",
    "                    if pd.notna(row.get('context', '')) and pd.notna(row.get('question', '')):\n",
    "                        context, question = str(row['context']).strip(), str(row['question']).strip()\n",
    "                        if context and question and len(self.tokenizer.encode(context)) < 512:\n",
    "                            contexts.append(context)\n",
    "                            questions.append(question)\n",
    "                logger.info(f\"Loaded {len(contexts)} samples from MCTest\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "        else:\n",
    "            logger.warning(f\"File not found: {file_path}\")\n",
    "        return contexts, questions\n",
    "\n",
    "    def load_squad(self, file_path: str) -> Tuple[List[str], List[str]]:\n",
    "        contexts, questions = [], []\n",
    "        if os.path.exists(file_path):\n",
    "            logger.info(f\"Loading SQuAD from: {file_path}\")\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding='utf-8')\n",
    "                for _, row in df.iterrows():\n",
    "                    if pd.notna(row.get('context', '')) and pd.notna(row.get('question', '')):\n",
    "                        context, question = str(row['context']).strip(), str(row['question']).strip()\n",
    "                        if context and question and len(self.tokenizer.encode(context)) < 512:\n",
    "                            contexts.append(context)\n",
    "                            questions.append(question)\n",
    "                logger.info(f\"Loaded {len(contexts)} samples from SQuAD\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {e}\")\n",
    "        else:\n",
    "            logger.warning(f\"File not found: {file_path}\")\n",
    "        return contexts, questions\n",
    "\n",
    "    def load_all_datasets(self) -> Tuple[List[str], List[str], List[str], List[str]]:\n",
    "        all_train_contexts, all_train_questions = [], []\n",
    "        all_val_contexts, all_val_questions = [], []\n",
    "\n",
    "        datasets = {\n",
    "            \"FairytaleQA\": (self.load_fairytale_qa, (\"FairytaleQA_train.csv\", \"FairytaleQA_validation.csv\")),\n",
    "            \"MCTest\": (self.load_mctest, (\"mctest_train.csv\", \"mctest_validation.csv\")),\n",
    "            \"SQuAD\": (self.load_squad, (\"squad_train_v1.csv\", \"squad_validation_v1.csv\")),\n",
    "        }\n",
    "\n",
    "        for name, (loader_fn, (train_file, val_file)) in datasets.items():\n",
    "            train_c, train_q = loader_fn(os.path.join(self.data_dir, train_file))\n",
    "            val_c, val_q = loader_fn(os.path.join(self.data_dir, val_file))\n",
    "            all_train_contexts.extend(train_c)\n",
    "            all_train_questions.extend(train_q)\n",
    "            all_val_contexts.extend(val_c)\n",
    "            all_val_questions.extend(val_q)\n",
    "\n",
    "        logger.info(f\"Loaded {len(all_train_contexts)} training samples and {len(all_val_contexts)} validation samples\")\n",
    "\n",
    "        train_combined = list(zip(all_train_contexts, all_train_questions))\n",
    "        val_combined = list(zip(all_val_contexts, all_val_questions))\n",
    "        random.shuffle(train_combined)\n",
    "        random.shuffle(val_combined)\n",
    "\n",
    "        if train_combined:\n",
    "            all_train_contexts, all_train_questions = zip(*train_combined)\n",
    "        if val_combined:\n",
    "            all_val_contexts, all_val_questions = zip(*val_combined)\n",
    "\n",
    "        return (list(all_train_contexts), list(all_train_questions),\n",
    "                list(all_val_contexts), list(all_val_questions))\n",
    "\n",
    "class AdvancedEvaluationMetrics:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "        self.smoothing = SmoothingFunction().method1\n",
    "\n",
    "    def compute_bleu(self, references, predictions):\n",
    "        bleu_scores = {f\"bleu_{i}\": [] for i in range(1, 5)}\n",
    "        for ref, pred in zip(references, predictions):\n",
    "            ref_tokens, pred_tokens = ref.split(), pred.split()\n",
    "            for i in range(1, 5):\n",
    "                weights = [1/i] * i\n",
    "                score = sentence_bleu([ref_tokens], pred_tokens, weights=weights, smoothing_function=self.smoothing)\n",
    "                bleu_scores[f\"bleu_{i}\"].append(score)\n",
    "        return {k: np.mean(v) for k, v in bleu_scores.items()}\n",
    "\n",
    "    def compute_rouge_l(self, references, predictions):\n",
    "        scores = [self.rouge_scorer.score(ref, pred)['rougeL'].fmeasure for ref, pred in zip(references, predictions)]\n",
    "        return {\"rouge_l\": np.mean(scores)}\n",
    "\n",
    "    def compute_meteor(self, references, predictions):\n",
    "        try:\n",
    "            meteor = evaluate.load(\"meteor\")\n",
    "            return {\"meteor\": meteor.compute(predictions=predictions, references=references)[\"meteor\"]}\n",
    "        except Exception:\n",
    "            return {\"meteor\": 0.0}\n",
    "\n",
    "    def compute_bert_score(self, references, predictions):\n",
    "        try:\n",
    "            P, R, F1 = bert_score.score(predictions, references, lang=\"en\", verbose=False)\n",
    "            return {\"bert_score\": F1.mean().item()}\n",
    "        except Exception:\n",
    "            return {\"bert_score\": 0.0}\n",
    "\n",
    "    # --- MODIFICATION 1: SELF-BLEU FIXED ---\n",
    "    def compute_self_bleu(self, predictions):\n",
    "        if len(predictions) < 2: return {\"self_bleu\": 0.0}\n",
    "        scores = []\n",
    "        for i, pred in enumerate(predictions):\n",
    "            others = predictions[:i] + predictions[i+1:]\n",
    "            pred_tokens = pred.split()\n",
    "            # The fix: Using all other sentences, not just the first 10\n",
    "            other_tokens = [other.split() for other in others]\n",
    "            if other_tokens:\n",
    "                score = sentence_bleu(other_tokens, pred_tokens, smoothing_function=self.smoothing)\n",
    "                scores.append(score)\n",
    "        return {\"self_bleu\": np.mean(scores) if scores else 0.0}\n",
    "\n",
    "    def compute_distinct_n(self, predictions, n):\n",
    "        all_ngrams = [tuple(tokens[i:i+n]) for pred in predictions for tokens in [pred.split()] for i in range(len(tokens)-n+1)]\n",
    "        if not all_ngrams: return 0.0\n",
    "        return len(set(all_ngrams)) / len(all_ngrams)\n",
    "\n",
    "    def compute_all_metrics(self, references, predictions):\n",
    "        if not references or not predictions:\n",
    "            return {m: 0.0 for m in [\"bleu_1\", \"bleu_2\", \"bleu_3\", \"bleu_4\", \"rouge_l\", \"meteor\", \"bert_score\", \"self_bleu\", \"distinct_1\", \"distinct_2\"]}\n",
    "        \n",
    "        metrics = {}\n",
    "        logger.info(\"Computing quality and diversity metrics...\")\n",
    "        metrics.update(self.compute_bleu(references, predictions))\n",
    "        metrics.update(self.compute_rouge_l(references, predictions))\n",
    "        metrics.update(self.compute_meteor(references, predictions))\n",
    "        metrics.update(self.compute_bert_score(references, predictions))\n",
    "        metrics.update(self.compute_self_bleu(predictions))\n",
    "        metrics[\"distinct_1\"] = self.compute_distinct_n(predictions, 1)\n",
    "        metrics[\"distinct_2\"] = self.compute_distinct_n(predictions, 2)\n",
    "        return metrics\n",
    "\n",
    "class DiverseDecoder:\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def diverse_generate(self, input_ids, attention_mask, num_return_sequences=1):\n",
    "        outputs = self.model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            max_length=128,\n",
    "            num_beams=8,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            num_beam_groups=4,\n",
    "            diversity_penalty=1.5,\n",
    "            no_repeat_ngram_size=2,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=self.tokenizer.pad_token_id,\n",
    "            eos_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "class MetricsLogger:\n",
    "    def __init__(self):\n",
    "        self.evaluation_history = []\n",
    "\n",
    "    def log_epoch_progress(self, epoch, loss, learning_rate):\n",
    "        logger.info(f\"Epoch {epoch:>.2f} | Loss: {loss:.4f} | LR: {learning_rate:.2e}\")\n",
    "\n",
    "    def log_evaluation(self, metrics, epoch=None, step=None):\n",
    "        eval_record = {'epoch': epoch, 'step': step, 'timestamp': datetime.now(), **metrics}\n",
    "        self.evaluation_history.append(eval_record)\n",
    "        self.display_metrics_table(metrics, epoch)\n",
    "\n",
    "    def display_metrics_table(self, metrics, epoch=None, step=None):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"EVALUATION RESULTS - Epoch {epoch}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        quality = {k: v for k, v in metrics.items() if any(x in k for x in ['bleu', 'rouge', 'meteor', 'bert_score'])}\n",
    "        diversity = {k: v for k, v in metrics.items() if any(x in k for x in ['self_bleu', 'distinct'])}\n",
    "        other = {k: v for k, v in metrics.items() if k not in quality and k not in diversity}\n",
    "        \n",
    "        for title, metric_dict in [(\"QUALITY\", quality), (\"DIVERSITY\", diversity), (\"OTHER\", other)]:\n",
    "            if metric_dict:\n",
    "                print(f\"\\n{title} METRICS:\")\n",
    "                table_data = [[k.replace('eval_', '').replace('_', '-').upper(), f\"{v:.4f}\"] for k, v in metric_dict.items()]\n",
    "                print(tabulate(table_data, headers=['Metric', 'Score'], tablefmt='grid'))\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    def display_training_summary(self):\n",
    "        if not self.evaluation_history: return\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"TRAINING SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "        eval_logs = [log for log in self.evaluation_history if 'eval_bleu_4' in log]\n",
    "        if not eval_logs: return\n",
    "        \n",
    "        best_bleu4 = max(eval_logs, key=lambda x: x.get('eval_bleu_4', 0))\n",
    "        best_rouge = max(eval_logs, key=lambda x: x.get('eval_rouge_l', 0))\n",
    "        best_meteor = max(eval_logs, key=lambda x: x.get('eval_meteor', 0))\n",
    "        \n",
    "        summary_data = [\n",
    "            ['Best BLEU-4', f\"{best_bleu4.get('eval_bleu_4', 0):.4f}\", f\"Epoch {best_bleu4.get('epoch', 'N/A')}\"],\n",
    "            ['Best ROUGE-L', f\"{best_rouge.get('eval_rouge_l', 0):.4f}\", f\"Epoch {best_rouge.get('epoch', 'N/A')}\"],\n",
    "            ['Best METEOR', f\"{best_meteor.get('eval_meteor', 0):.4f}\", f\"Epoch {best_meteor.get('epoch', 'N/A')}\"],\n",
    "        ]\n",
    "        print(tabulate(summary_data, headers=['Metric', 'Best Score', 'Achieved At'], tablefmt='grid'))\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "class CustomLoggingCallback(TrainerCallback):\n",
    "    def __init__(self, metrics_logger=None):\n",
    "        self.metrics_logger = metrics_logger if metrics_logger is not None else MetricsLogger()\n",
    "\n",
    "    def on_log(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs=None, **kwargs):\n",
    "        if state.is_world_process_zero and logs:\n",
    "            eval_metrics = {k: v for k, v in logs.items() if k.startswith(\"eval_\") and isinstance(v, (int, float))}\n",
    "            if eval_metrics:\n",
    "                self.metrics_logger.log_evaluation(\n",
    "                    metrics=eval_metrics,\n",
    "                    epoch=int(logs.get('epoch', state.epoch or 0)),\n",
    "                    step=state.global_step\n",
    "                )\n",
    "            elif any(key in logs for key in ['train_loss', 'loss']) and 'learning_rate' in logs:\n",
    "                loss = logs.get('train_loss', logs.get('loss', 0))\n",
    "                self.metrics_logger.log_epoch_progress(\n",
    "                    epoch=logs.get('epoch', state.epoch or 0),\n",
    "                    loss=loss,\n",
    "                    learning_rate=logs['learning_rate']\n",
    "                )\n",
    "\n",
    "    def on_train_end(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, **kwargs):\n",
    "        if state.is_world_process_zero:\n",
    "            self.metrics_logger.display_training_summary()\n",
    "\n",
    "# --- MODIFICATION 2, PART 1: ADD NEW CALLBACK CLASS ---\n",
    "class AverageTrainLossLogger(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.epoch_train_losses = []\n",
    "\n",
    "    def on_epoch_begin(self, args, state, control, **kwargs):\n",
    "        \"\"\"Reset the list of losses at the start of each epoch.\"\"\"\n",
    "        self.epoch_train_losses = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"On each log step, if it's a training log, append the loss.\"\"\"\n",
    "        if 'loss' in logs and 'learning_rate' in logs:\n",
    "            self.epoch_train_losses.append(logs['loss'])\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        \"\"\"At the end of the epoch, calculate and log the average.\"\"\"\n",
    "        if self.epoch_train_losses:\n",
    "            avg_epoch_loss = np.mean(self.epoch_train_losses)\n",
    "            logger.info(f\"===== Average Training Loss for Epoch {int(state.epoch)}: {avg_epoch_loss:.4f} =====\")\n",
    "\n",
    "# --- NEW: CALLBACK FOR OPTUNA PRUNING ---\n",
    "class OptunaPruningCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    A TrainerCallback to report evaluation metrics to Optuna for pruning.\n",
    "    \"\"\"\n",
    "    def __init__(self, trial: optuna.Trial):\n",
    "        self.trial = trial\n",
    "\n",
    "    def on_evaluate(self, args: TrainingArguments, state: TrainerState, control: TrainerControl, metrics: dict, **kwargs):\n",
    "        # We report the metric we're optimizing for (bleu_4)\n",
    "        if \"eval_bleu_4\" in metrics:\n",
    "            metric_value = metrics[\"eval_bleu_4\"]\n",
    "            self.trial.report(metric_value, state.global_step)\n",
    "            \n",
    "            # Check if the trial should be pruned\n",
    "            if self.trial.should_prune():\n",
    "                logger.warning(f\"Trial {self.trial.number} pruned at step {state.global_step} with BLEU-4: {metric_value}.\")\n",
    "                raise optuna.TrialPruned()\n",
    "        elif \"eval_loss\" in metrics:\n",
    "            # Fallback to loss if bleu_4 isn't available for some reason\n",
    "            self.trial.report(metrics[\"eval_loss\"], state.global_step)\n",
    "            if self.trial.should_prune():\n",
    "                logger.warning(f\"Trial {self.trial.number} pruned at step {state.global_step} with Loss: {metrics['eval_loss']}.\")\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "def log_gpu_memory(prefix=\"\"):\n",
    "    \"\"\"Log current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        logger.info(f\"{prefix} GPU Memory - Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB\")\n",
    "    else:\n",
    "        logger.info(f\"{prefix} GPU not available\")\n",
    "\n",
    "def log_model_state(model, prefix=\"\"):\n",
    "    \"\"\"Log current model state\"\"\"\n",
    "    logger.info(f\"{prefix} Model - Training mode: {model.training}, Device: {next(model.parameters()).device}\")\n",
    "\n",
    "# --- MODIFIED: CustomTrainer now accepts an `is_tuning_trial` flag ---\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, evaluator, metrics_logger=None, is_tuning_trial=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.evaluator = evaluator\n",
    "        self.decoder = DiverseDecoder(self.model, self.processing_class)\n",
    "        self.metrics_logger = metrics_logger or MetricsLogger()\n",
    "        self.is_tuning_trial = is_tuning_trial  # <-- Store the flag\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        # --- MODIFIED: Check if we are in a tuning trial ---\n",
    "        if self.is_tuning_trial:\n",
    "            logger.info(f\"=== TUNING TRIAL EVALUATION (BLEU-4 Only) ===\")\n",
    "        else:\n",
    "            logger.info(\"=== BEFORE EVALUATION ===\")\n",
    "            log_gpu_memory(\"BEFORE EVAL\")\n",
    "            log_model_state(self.model, \"BEFORE EVAL\")\n",
    "        \n",
    "        eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
    "        self.model.eval()\n",
    "        \n",
    "        predictions, references = [], []\n",
    "        total_loss = 0.0\n",
    "        num_batches = 0\n",
    "        \n",
    "        epoch = self.state.epoch if self.state.epoch is not None else 0\n",
    "        if not self.is_tuning_trial:\n",
    "             logger.info(\"Starting evaluation on full validation set...\")\n",
    "        \n",
    "        eval_desc = f\"Evaluating Epoch {int(epoch)}\"\n",
    "        if self.is_tuning_trial:\n",
    "            eval_desc = f\"Tuning Trial {self.state.trial_number} Eval\" if hasattr(self.state, 'trial_number') else \"Tuning Trial Eval\"\n",
    "            \n",
    "        eval_progress = tqdm(eval_dataloader, desc=eval_desc, unit=\"batch\", disable=False) # Disable tqdm in tuning\n",
    "\n",
    "        try:\n",
    "            for batch_idx, batch in enumerate(eval_progress):\n",
    "                batch_device = {k: v.to(self.args.device) for k, v in batch.items()}\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(**batch_device)\n",
    "                    total_loss += outputs.loss.item()\n",
    "                    num_batches += 1\n",
    "                    \n",
    "                    inputs = {k: v for k, v in batch_device.items() if k != \"labels\"}\n",
    "                    generated_ids = self.decoder.diverse_generate(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n",
    "                    batch_predictions = self.processing_class.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                    predictions.extend(batch_predictions)\n",
    "                    \n",
    "                    labels = batch[\"labels\"].cpu().numpy()\n",
    "                    labels = np.where(labels != -100, labels, self.processing_class.pad_token_id)\n",
    "                    batch_references = self.processing_class.batch_decode(labels, skip_special_tokens=True)\n",
    "                    references.extend(batch_references)\n",
    "                    \n",
    "                    if (batch_idx + 1) % 20 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during evaluation: {e}\")\n",
    "            return {f\"{metric_key_prefix}_loss\": float('inf')}\n",
    "\n",
    "        # --- MODIFIED: Conditional metric computation ---\n",
    "        metrics = {}\n",
    "        if self.is_tuning_trial:\n",
    "            # For tuning, ONLY compute loss and BLEU-4\n",
    "            if not self.is_tuning_trial: logger.info(f\"Tuning trial: Computing only BLEU-4 for {len(predictions)} predictions...\")\n",
    "            bleu_scores = self.evaluator.compute_bleu(references, predictions)\n",
    "            metrics = {\n",
    "                f\"{metric_key_prefix}_bleu_4\": bleu_scores.get('bleu_4', 0.0)\n",
    "            }\n",
    "        else:\n",
    "            # Full evaluation for the final run\n",
    "            logger.info(f\"Computing metrics for {len(predictions)} predictions...\")\n",
    "            metrics = self.evaluator.compute_all_metrics(references, predictions)\n",
    "            metrics = {f\"{metric_key_prefix}_{k}\": v for k, v in metrics.items()}\n",
    "        # --- END OF MODIFICATION ---\n",
    "        \n",
    "        avg_loss = total_loss / max(num_batches, 1)\n",
    "        metrics[f\"{metric_key_prefix}_loss\"] = avg_loss\n",
    "        \n",
    "        self.log(metrics)\n",
    "        \n",
    "        del predictions, references, batch_device\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        if not self.is_tuning_trial:\n",
    "            logger.info(\"=== AFTER EVALUATION ===\")\n",
    "            log_gpu_memory(\"AFTER EVAL\")\n",
    "            log_model_state(self.model, \"AFTER EVAL\")\n",
    "            logger.info(f\"Evaluation completed successfully. Average loss: {avg_loss:.4f}\")\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "def generate_sample_predictions(model, tokenizer, eval_contexts, eval_questions, num_samples=20):\n",
    "    logger.info(\"Generating sample predictions...\")\n",
    "    indices = random.sample(range(len(eval_contexts)), min(num_samples, len(eval_contexts)))\n",
    "    model.eval()\n",
    "    decoder = DiverseDecoder(model, tokenizer)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"SAMPLE PREDICTIONS - 20 Context-Question Pairs\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    for i, idx in enumerate(indices, 1):\n",
    "        context, actual_question = eval_contexts[idx], eval_questions[idx]\n",
    "        input_text = f\"Generate a question from context: {context}\"\n",
    "        input_encoding = tokenizer(input_text, max_length=512, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_ids = decoder.diverse_generate(input_encoding[\"input_ids\"], input_encoding[\"attention_mask\"])\n",
    "            predicted_question = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\n--- SAMPLE {i:2d} ---\")\n",
    "        print(f\"CONTEXT: {context[:200]}{'...' if len(context) > 200 else ''}\")\n",
    "        print(f\"ACTUAL:   {actual_question}\")\n",
    "        print(f\"PREDICTED: {predicted_question}\")\n",
    "        print(\"-\" * 80)\n",
    "    print(\"=\"*100 + \"\\n\")\n",
    "\n",
    "def setup_training_args(output_dir, num_train_epochs=5, train_dataset_size=0):\n",
    "    effective_batch_size = 8 * 2\n",
    "    steps_per_epoch = max(1, train_dataset_size // effective_batch_size)\n",
    "    \n",
    "    logger.info(f\"Training Configuration: Dataset size: {train_dataset_size:,}, Effective batch size: {effective_batch_size}, Steps per epoch: {steps_per_epoch}\")\n",
    "    \n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        torch_compile=True,\n",
    "        learning_rate=5e-5,  # This will be overridden by Optuna\n",
    "        weight_decay=0.01, # This will be overridden by Optuna\n",
    "        warmup_steps=min(500, steps_per_epoch), # This will be overridden by Optuna\n",
    "        logging_steps=max(10, steps_per_epoch // 10),\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_bleu_4\",\n",
    "        greater_is_better=True,\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=True,\n",
    "        lr_scheduler_type=\"cosine\", # This will be overridden by Optuna\n",
    "        save_total_limit=3, # Will use 1 for tuning\n",
    "        report_to=\"none\",\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "        group_by_length=True,\n",
    "    )\n",
    "\n",
    "# --- NEW: Globals to hold data for Optuna trials ---\n",
    "# This avoids reloading data for every trial\n",
    "g_tokenizer = None\n",
    "g_model_name = \"google/flan-t5-base\"\n",
    "g_train_dataset = None\n",
    "g_eval_dataset = None\n",
    "g_data_collator = None\n",
    "g_evaluator = None\n",
    "g_eval_contexts = None\n",
    "g_eval_questions = None\n",
    "\n",
    "# --- NEW: Optuna Objective Function ---\n",
    "def objective(trial: optuna.Trial):\n",
    "    global g_tokenizer, g_model_name, g_train_dataset, g_eval_dataset, g_data_collator, g_evaluator\n",
    "    \n",
    "    logger.info(f\"--- Starting Optuna Trial {trial.number} ---\")\n",
    "    \n",
    "    # --- 1. Define Search Space ---\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-4, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 0.0, 0.1)\n",
    "    lr_scheduler_type = trial.suggest_categorical(\"lr_scheduler_type\", [\"linear\", \"cosine\", \"constant\"])\n",
    "    \n",
    "    # Calculate steps_per_epoch for warmup suggestion\n",
    "    effective_batch_size = 8 * 2\n",
    "    steps_per_epoch = max(1, len(g_train_dataset) // effective_batch_size)\n",
    "    warmup_steps = trial.suggest_int(\"warmup_steps\", 100, steps_per_epoch) \n",
    "    \n",
    "    # --- USE SMALL EVAL SUBSET FOR TUNING (e.g., 10% or 5000 samples max) ---\n",
    "    eval_subset_size = min(5000, int(len(g_eval_dataset) * 0.3))  # Use 10% of eval data, max 5000\n",
    "    eval_indices = random.sample(range(len(g_eval_dataset)), eval_subset_size)\n",
    "    eval_subset = torch.utils.data.Subset(g_eval_dataset, eval_indices)\n",
    "    \n",
    "    logger.info(f\"Trial {trial.number}: Using {len(g_train_dataset)} train samples and {eval_subset_size} eval samples (subset for speed)\")\n",
    "    \n",
    "    # --- 2. Configure Training ---\n",
    "    model = T5ForConditionalGeneration.from_pretrained(g_model_name)\n",
    "    if g_tokenizer.pad_token is not None and g_tokenizer.pad_token_id > g_tokenizer.vocab_size:\n",
    "         model.resize_token_embeddings(len(g_tokenizer))\n",
    "    \n",
    "    output_dir = f\"./optuna-trials/trial_{trial.number}\"\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=8,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=2,\n",
    "        gradient_accumulation_steps=2,\n",
    "        torch_compile=True,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_steps=warmup_steps,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        logging_steps=max(10, steps_per_epoch // 10),\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_bleu_4\",\n",
    "        greater_is_better=True,\n",
    "        bf16=torch.cuda.is_bf16_supported(),\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=True,\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\",\n",
    "        seed=42,\n",
    "        data_seed=42,\n",
    "        group_by_length=True,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "    )\n",
    "    \n",
    "    pruning_callback = OptunaPruningCallback(trial)\n",
    "    trial_data_collator = DataCollatorForSeq2Seq(tokenizer=g_tokenizer, model=model, padding=True, max_length=512, label_pad_token_id=-100)\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        evaluator=g_evaluator,\n",
    "        metrics_logger=None,\n",
    "        is_tuning_trial=True,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=g_train_dataset,  # Full training data\n",
    "        eval_dataset=eval_subset,        # <--- SUBSET for fast evaluation\n",
    "        tokenizer=g_tokenizer,\n",
    "        data_collator=trial_data_collator,\n",
    "        callbacks=[\n",
    "            pruning_callback,\n",
    "            EarlyStoppingCallback(early_stopping_patience=4)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    trainer.state.trial_number = trial.number\n",
    "    \n",
    "    # --- 3. Train ---\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except optuna.TrialPruned:\n",
    "        logger.info(f\"Trial {trial.number} was pruned.\")\n",
    "        del model, trainer, trial_data_collator\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in trial {trial.number}: {e}\")\n",
    "        del model, trainer, trial_data_collator\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        return 0.0\n",
    "\n",
    "    # --- 4. Report & Return ---\n",
    "    best_metric = trainer.state.best_metric\n",
    "    logger.info(f\"--- Finished Optuna Trial {trial.number} | Best BLEU-4: {best_metric} ---\")\n",
    "    \n",
    "    del model, trainer, trial_data_collator\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return best_metric if best_metric is not None else 0.0\n",
    "\n",
    "\n",
    "# --- MODIFIED: Main function now orchestrates setup, tuning, and final training ---\n",
    "def main():\n",
    "    global g_tokenizer, g_model_name, g_train_dataset, g_eval_dataset, g_data_collator, g_evaluator, g_eval_contexts, g_eval_questions\n",
    "    \n",
    "    set_seed(42)\n",
    "    logger.info(\"Starting T5 Question Generation Training\")\n",
    "    \n",
    "    data_dir = \"E:/A_CSE499/data\" # <-- Set your data directory\n",
    "    output_dir = \"./t5-flan-question-generation-tuned\" # For the *final* model\n",
    "\n",
    "    # --- 1. SETUP (Done ONCE) ---\n",
    "    logger.info(f\"Loading model and tokenizer: {g_model_name}...\")\n",
    "    g_tokenizer = T5Tokenizer.from_pretrained(g_model_name)\n",
    "    \n",
    "    # We load a dummy model here just to resize embeddings if needed\n",
    "    # and to create the *global* data collator.\n",
    "    # The *actual* model for training will be loaded in the objective/final run.\n",
    "    dummy_model = T5ForConditionalGeneration.from_pretrained(g_model_name)\n",
    "    if g_tokenizer.pad_token is None:\n",
    "        g_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        dummy_model.resize_token_embeddings(len(g_tokenizer))\n",
    "    \n",
    "    logger.info(\"Loading and processing datasets...\")\n",
    "    data_processor = DataProcessor(data_dir, g_tokenizer)\n",
    "    train_contexts, train_questions, g_eval_contexts, g_eval_questions = data_processor.load_all_datasets()\n",
    "    \n",
    "    if not train_contexts:\n",
    "        logger.error(\"No training data loaded! Please check data directory.\")\n",
    "        return\n",
    "        \n",
    "    g_train_dataset = QuestionGenerationDataset(train_contexts, train_questions, g_tokenizer)\n",
    "    g_eval_dataset = QuestionGenerationDataset(g_eval_contexts, g_eval_questions, g_tokenizer)\n",
    "    \n",
    "    # This collator is used by the objective function, but needs a model\n",
    "    g_data_collator = DataCollatorForSeq2Seq(tokenizer=g_tokenizer, model=dummy_model, padding=True, max_length=512, label_pad_token_id=-100)\n",
    "    del dummy_model # We don't need this anymore\n",
    "    \n",
    "    g_evaluator = AdvancedEvaluationMetrics(g_tokenizer)\n",
    "    \n",
    "    # --- 2. OPTUNA TUNING ---\n",
    "    logger.info(\"=== STARTING HYPERPARAMETER TUNING ===\")\n",
    "    \n",
    "    # Use TPE Sampler (Bayesian)\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    # Prune trials that are performing worse than the median\n",
    "    pruner = optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=3) # Prune after 1 epoch (n_warmup_steps=1)\n",
    "    \n",
    "    # Create study with checkpointing\n",
    "    study = optuna.create_study(\n",
    "        study_name=\"t5-qg-tuning\",\n",
    "        direction=\"maximize\", # We want to maximize BLEU-4\n",
    "        sampler=sampler,\n",
    "        pruner=pruner,\n",
    "        storage=\"sqlite:///t5_qg_tuning.db\", # This file enables resuming\n",
    "        load_if_exists=True # Resume from checkpoint\n",
    "    )\n",
    "    \n",
    "    n_trials = 10\n",
    "    n_completed_trials = len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n",
    "    \n",
    "    if n_completed_trials >= n_trials:\n",
    "        logger.info(f\"Study already has {n_completed_trials} completed trials. Skipping optimization.\")\n",
    "    else:\n",
    "        n_remaining_trials = n_trials - n_completed_trials\n",
    "        logger.info(f\"Resuming study. {n_completed_trials} trials complete, running {n_remaining_trials} more.\")\n",
    "        try:\n",
    "            study.optimize(objective, n_trials=n_remaining_trials) # e.g., 12h timeout\n",
    "        except KeyboardInterrupt:\n",
    "            logger.warning(\"Optuna optimization interrupted.\")\n",
    "    \n",
    "    logger.info(\"=== TUNING COMPLETE ===\")\n",
    "    best_trial = study.best_trial\n",
    "    logger.info(f\"Best trial number: {best_trial.number}\")\n",
    "    logger.info(f\"Best BLEU-4: {best_trial.value:.4f}\")\n",
    "    logger.info(f\"Best hyperparameters: {json.dumps(best_trial.params, indent=2)}\")\n",
    "\n",
    "    # --- 3. FINAL TRAINING ---\n",
    "    logger.info(\"=== STARTING FINAL TRAINING WITH BEST HYPERPARAMETERS ===\")\n",
    "    \n",
    "    best_params = best_trial.params\n",
    "    \n",
    "    # Load the final model to be trained\n",
    "    model = T5ForConditionalGeneration.from_pretrained(g_model_name)\n",
    "    if g_tokenizer.pad_token is not None and g_tokenizer.pad_token_id > g_tokenizer.vocab_size:\n",
    "         model.resize_token_embeddings(len(g_tokenizer))\n",
    "         \n",
    "    shared_metrics_logger = MetricsLogger()\n",
    "    custom_logging_callback = CustomLoggingCallback(shared_metrics_logger)\n",
    "    avg_loss_callback = AverageTrainLossLogger()\n",
    "    \n",
    "    # Use the original setup_training_args\n",
    "    training_args = setup_training_args(\n",
    "        output_dir,\n",
    "        num_train_epochs=8, # From original config\n",
    "        train_dataset_size=len(g_train_dataset)\n",
    "    )\n",
    "    \n",
    "    # Override args with best params from the study\n",
    "    training_args.learning_rate = best_params[\"learning_rate\"]\n",
    "    training_args.weight_decay = best_params[\"weight_decay\"]\n",
    "    training_args.warmup_steps = best_params[\"warmup_steps\"]\n",
    "    training_args.lr_scheduler_type = best_params[\"lr_scheduler_type\"]\n",
    "    \n",
    "    # Re-create the data collator with the *final* model instance\n",
    "    final_data_collator = DataCollatorForSeq2Seq(tokenizer=g_tokenizer, model=model, padding=True, max_length=512, label_pad_token_id=-100)\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        evaluator=g_evaluator,\n",
    "        metrics_logger=shared_metrics_logger,\n",
    "        is_tuning_trial=False, # <--- IMPORTANT: Run full evaluation\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=g_train_dataset,\n",
    "        eval_dataset=g_eval_dataset,\n",
    "        tokenizer=g_tokenizer,\n",
    "        data_collator=final_data_collator,\n",
    "        callbacks=[\n",
    "            custom_logging_callback,\n",
    "            avg_loss_callback,\n",
    "            EarlyStoppingCallback(early_stopping_patience=4)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    logger.info(\"=== FINAL TRAINING START ===\")\n",
    "    log_gpu_memory(\"FINAL TRAINING START\")\n",
    "    log_model_state(model, \"FINAL TRAINING START\")\n",
    "    \n",
    "    logger.info(\"Starting final training...\")\n",
    "    try:\n",
    "        trainer.train()\n",
    "    except KeyboardInterrupt:\n",
    "        logger.warning(\"Final training interrupted. Saving current model...\")\n",
    "        trainer.save_model(os.path.join(output_dir, \"interrupted\"))\n",
    "        return\n",
    "    \n",
    "    logger.info(\"Saving final model...\")\n",
    "    trainer.save_model(os.path.join(output_dir, \"final\"))\n",
    "    g_tokenizer.save_pretrained(os.path.join(output_dir, \"final\"))\n",
    "    \n",
    "    logger.info(\"Performing final comprehensive evaluation...\")\n",
    "    final_metrics = trainer.evaluate()\n",
    "    \n",
    "    generate_sample_predictions(model, g_tokenizer, g_eval_contexts, g_eval_questions)\n",
    "    \n",
    "    print(\"\\n\" + \"*\"*40)\n",
    "    print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"*\"*40)\n",
    "    \n",
    "    final_results = [[k.replace('eval_', '').upper(), f\"{v:.4f}\"] for k, v in sorted(final_metrics.items()) if isinstance(v, (int, float))]\n",
    "    if final_results:\n",
    "        print(\"\\nFINAL EVALUATION RESULTS (using best params):\")\n",
    "        print(tabulate(final_results, headers=['Metric', 'Final Score'], tablefmt='fancy_grid'))\n",
    "    \n",
    "    logger.info(\"Training pipeline completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
